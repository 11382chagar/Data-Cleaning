{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb97362",
   "metadata": {},
   "source": [
    "# Data Cleaning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c981d",
   "metadata": {},
   "source": [
    "## Cafe Sales\n",
    "\n",
    "This project will show how I go about injesting, investigating and cleaning dirty data. The finished product will be a clean data set that can be used for futher analysis or other data projects. The data used is the cafe sales data dowloaded from Kaggle at the following location: https://www.kaggle.com/datasets/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training\n",
    "\n",
    "For the purposes of this exercise, I have decided that the cafe wants to understand which location is the most lucrative (how much is spent in each location) and which products are most popular (how many are bought in each location) in each location. Date isn't necessarily important for the moment, however it may be down the line. This will guide further analysis in the future, however for this excercise, it will help us understand which parts of the data are important and which aren't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9eca3",
   "metadata": {},
   "source": [
    "### 1.0 Data Injestion & Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794f3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries - these are the standard libraries that I tend to import for all projects regardless of what I'm doing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9095cdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
       "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
       "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
       "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
       "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  In-store       2023-05-16  \n",
       "2  In-store       2023-07-19  \n",
       "3   UNKNOWN       2023-04-27  \n",
       "4  In-store       2023-06-11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the data set and saving as a DataFrame that we wont touch\n",
    "orig_sales = pd.read_csv('cafe_sales_data.csv')\n",
    "\n",
    "# Creating a copy of the DataFrame to work with\n",
    "sales = orig_sales.copy()\n",
    "\n",
    "# Viewd the DataFrame\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788a416",
   "metadata": {},
   "source": [
    "Straight out of the gate we can see some issues with the data, in both payment method and location there are 'UNKNOWN' values and we have an 'ERROR' in the total spend column. I will have to dive a little deeper to understand how many occurences there are of each of these and if there are any other anomalies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249c445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    10000 non-null  object\n",
      " 1   Item              9667 non-null   object\n",
      " 2   Quantity          9862 non-null   object\n",
      " 3   Price Per Unit    9821 non-null   object\n",
      " 4   Total Spent       9827 non-null   object\n",
      " 5   Payment Method    7421 non-null   object\n",
      " 6   Location          6735 non-null   object\n",
      " 7   Transaction Date  9841 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the metadata of the DataFrame\n",
    "sales.info()\n",
    "\n",
    "# Check the shape of the DataFrame\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416360ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction ID      object\n",
       "Item                object\n",
       "Quantity            object\n",
       "Price Per Unit      object\n",
       "Total Spent         object\n",
       "Payment Method      object\n",
       "Location            object\n",
       "Transaction Date    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data types\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbf0bc",
   "metadata": {},
   "source": [
    "Again, we can see there are some formatting errors. The obvious one is the date column which is currently an object. We would like this to be a datetime data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee50ca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction ID         0\n",
       "Item                 333\n",
       "Quantity             138\n",
       "Price Per Unit       179\n",
       "Total Spent          173\n",
       "Payment Method      2579\n",
       "Location            3265\n",
       "Transaction Date     159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values in the DataFrame\n",
    "sales.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4a461",
   "metadata": {},
   "source": [
    "We can see that there are nulls in every column. Now there are many ways we can deal with these, particularly in the numerical columns. I think we have to understand the data a little better to make a decision on what to do with these nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7098ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for dup;icate values\n",
    "sales.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556ac07",
   "metadata": {},
   "source": [
    "No duplicates, thats a positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a17dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>9667</td>\n",
       "      <td>9862</td>\n",
       "      <td>9821</td>\n",
       "      <td>9827</td>\n",
       "      <td>7421</td>\n",
       "      <td>6735</td>\n",
       "      <td>9841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Juice</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1171</td>\n",
       "      <td>2013</td>\n",
       "      <td>2429</td>\n",
       "      <td>979</td>\n",
       "      <td>2291</td>\n",
       "      <td>3022</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Transaction ID   Item Quantity Price Per Unit Total Spent  \\\n",
       "count           10000   9667     9862           9821        9827   \n",
       "unique          10000     10        7              8          19   \n",
       "top       TXN_1961373  Juice        5            3.0         6.0   \n",
       "freq                1   1171     2013           2429         979   \n",
       "\n",
       "        Payment Method  Location Transaction Date  \n",
       "count             7421      6735             9841  \n",
       "unique               5         4              367  \n",
       "top     Digital Wallet  Takeaway          UNKNOWN  \n",
       "freq              2291      3022              159  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally we'll look at some summary statistics of the data\n",
    "sales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df94b3b9",
   "metadata": {},
   "source": [
    "Not massively helpful or insightful, but gives us a visualisation of the number of data points in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923bdcc",
   "metadata": {},
   "source": [
    "### 2.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e445e11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_id', 'item', 'quantity', 'price', 'spent', 'pay_method',\n",
       "       'location', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the columns to make the data easier to work with\n",
    "sales.rename(columns={'Transaction ID': 'transaction_id',\n",
    "                 'Item': 'item',\n",
    "                 'Quantity': 'quantity',\n",
    "                 'Price Per Unit': 'price',\n",
    "                 'Total Spent': 'spent',\n",
    "                 'Payment Method': 'pay_method',\n",
    "                 'Location': 'location',\n",
    "                 'Transaction Date': 'date'}, inplace=True)\n",
    "\n",
    "# check the columns\n",
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4f18422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id    10000\n",
       "item                 10\n",
       "quantity              7\n",
       "price                 8\n",
       "spent                19\n",
       "pay_method            5\n",
       "location              4\n",
       "date                367\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "sales.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79439419",
   "metadata": {},
   "source": [
    "### 2.1: Column by column cleaning\n",
    "I'll go through each column that will be important to our analysis and correct any issues, change data types if necessary and/or remove any erroneous entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9868311",
   "metadata": {},
   "source": [
    "#### 2.1.1: Items & Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570529a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Coffee', 'Cake', 'Cookie', 'Salad', 'Smoothie', 'UNKNOWN',\n",
       "       'Sandwich', nan, 'ERROR', 'Juice', 'Tea'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking each of the individual items\n",
    "sales['item'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8a565",
   "metadata": {},
   "source": [
    "We can see there some erroneous entries in the item column, but using the price column, we may be able to workout what these erroneous entries are (assuming that each item has a unique price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dcb6d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item\n",
       "Cake                               [3.0, nan, UNKNOWN, ERROR]\n",
       "Coffee                             [2.0, nan, ERROR, UNKNOWN]\n",
       "Cookie                             [1.0, UNKNOWN, nan, ERROR]\n",
       "ERROR       [1.5, 3.0, 5.0, nan, 4.0, 2.0, 1.0, UNKNOWN, E...\n",
       "Juice                              [3.0, nan, UNKNOWN, ERROR]\n",
       "Salad                              [5.0, ERROR, UNKNOWN, nan]\n",
       "Sandwich                           [4.0, nan, ERROR, UNKNOWN]\n",
       "Smoothie                           [4.0, nan, UNKNOWN, ERROR]\n",
       "Tea                                [1.5, nan, ERROR, UNKNOWN]\n",
       "UNKNOWN     [3.0, 1.0, 5.0, 4.0, 1.5, 2.0, nan, UNKNOWN, E...\n",
       "Name: price, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique price points of the items\n",
    "sales.groupby('item')['price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf297c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item\n",
       "Cake                                  [3.0]\n",
       "Coffee                                [2.0]\n",
       "Cookie                                [1.0]\n",
       "ERROR       [3.0, nan, 4.0, UNKNOWN, ERROR]\n",
       "Juice                                 [3.0]\n",
       "Salad                                 [5.0]\n",
       "Sandwich                              [4.0]\n",
       "Smoothie                              [4.0]\n",
       "Tea                                   [1.5]\n",
       "UNKNOWN     [3.0, 4.0, nan, UNKNOWN, ERROR]\n",
       "Name: price, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing the error, unknown and nan values in price with the correct values\n",
    "sales.loc[sales['item'] == 'Cake', 'price'] = '3.0'\n",
    "sales.loc[sales['item'] == 'Coffee', 'price'] = '2.0'\n",
    "sales.loc[sales['item'] == 'Cookie', 'price'] = '1.0'\n",
    "sales.loc[sales['item'] == 'Juice', 'price'] = '3.0'\n",
    "sales.loc[sales['item'] == 'Salad', 'price'] = '5.0'\n",
    "sales.loc[sales['item'] == 'Sandwich', 'price'] = '4.0'\n",
    "sales.loc[sales['item'] == 'Smoothie', 'price'] = '4.0'\n",
    "sales.loc[sales['item'] == 'Tea', 'price'] = '1.5'\n",
    "\n",
    "# Replacing the error, unknown and nan values in item with the correct values\n",
    "sales.loc[sales['price'] == '2.0', 'item'] = 'Coffee'\n",
    "sales.loc[sales['price'] == '1.0', 'item'] = 'Cookie'\n",
    "sales.loc[sales['price'] == '5.0', 'item'] = 'Salad'\n",
    "sales.loc[sales['price'] == '1.5', 'item'] = 'Tea'\n",
    "\n",
    "\n",
    "# Check the unique price points of the items again\n",
    "sales.groupby('item')['price'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285348f5",
   "metadata": {},
   "source": [
    "We did what we could with the information we had. Now the best thing to do is to remove the errors, unknowns and nan values from the item list and continue our data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b46531b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item\n",
       "Cake        1\n",
       "Coffee      1\n",
       "Cookie      1\n",
       "Juice       1\n",
       "Salad       1\n",
       "Sandwich    1\n",
       "Smoothie    1\n",
       "Tea         1\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the error, unknown and nan values in price and item\n",
    "sales = sales[~sales['item'].str.contains('UNKNOWN|ERROR', na=False)]\n",
    "sales = sales[~sales['price'].str.contains('UNKNOWN|ERROR', na=False)]\n",
    "sales = sales[~sales['item'].isnull()]\n",
    "\n",
    "# Check the number unique price points for the items\n",
    "sales.groupby('item')['price'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ba6cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id     object\n",
       "item               object\n",
       "quantity           object\n",
       "price             float64\n",
       "spent              object\n",
       "pay_method         object\n",
       "location           object\n",
       "date               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the data type of the price column to float\n",
    "sales['price'] = sales['price'].astype(float)\n",
    "\n",
    "# Check the data types of the DataFrame again\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7ac25",
   "metadata": {},
   "source": [
    "That's the item & price columns cleaned, lets continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adadbdad",
   "metadata": {},
   "source": [
    "#### 2.1.2: Quantity\n",
    "\n",
    "As this is a case by case data series, there really isn't much we can do other than drop any erroneous entries and change the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812dd8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '4', '5', '3', '1', 'ERROR', 'UNKNOWN', nan], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values in the quantity column\n",
    "sales['quantity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e08f258a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '4', '5', '3', '1'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the ERROR, UNKOWN and Nan values in the quantity column\n",
    "sales = sales[~sales['quantity'].str.contains('UNKNOWN|ERROR', na=False)]\n",
    "sales = sales[~sales['quantity'].isnull()]\n",
    "\n",
    "# Check the unique values in the quantity column again\n",
    "sales['quantity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e722046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id     object\n",
       "item               object\n",
       "quantity            int32\n",
       "price             float64\n",
       "spent              object\n",
       "pay_method         object\n",
       "location           object\n",
       "date               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the data type of quantity to int\n",
    "sales['quantity'] = sales['quantity'].astype(int)\n",
    "\n",
    "# Check the data types of the DataFrame again\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d2c6b",
   "metadata": {},
   "source": [
    "#### 2.1.3: Spent\n",
    "Again, this is a case by case series, however where we have both quantity and price (which we do because we've cleaned both of those columns) we can deduct a quantity spent for any erroneous entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c7a25ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4.0', '12.0', 'ERROR', '10.0', '20.0', '16.0', '25.0', '8.0',\n",
       "       '5.0', '3.0', '15.0', '6.0', nan, 'UNKNOWN', '2.0', '9.0', '1.0',\n",
       "       '7.5', '4.5', '1.5'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values in the quantity column\n",
    "sales['spent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f24727fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4.0', '12.0', 4.0, '10.0', '20.0', '16.0', '25.0', '8.0', '5.0',\n",
       "       '3.0', '15.0', '6.0', 12.0, 2.0, 3.0, '2.0', '9.0', '1.0', '7.5',\n",
       "       '4.5', 9.0, '1.5', 6.0, 20.0, 7.5, 15.0, 10.0, 25.0, 8.0, 1.0,\n",
       "       16.0, 1.5, 4.5, 5.0], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply price by quantity where spent contains ERROR, UNKNOWN or nan values\n",
    "sales.loc[sales['spent'].str.contains('UNKNOWN|ERROR', na=False), 'spent'] = sales['price'] * sales['quantity']\n",
    "sales.loc[sales['spent'].isnull(), 'spent'] = sales['price'] * sales['quantity']\n",
    "\n",
    "# Check the unique values in the spent column again\n",
    "sales['spent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53b78157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id     object\n",
       "item               object\n",
       "quantity            int32\n",
       "price             float64\n",
       "spent             float64\n",
       "pay_method         object\n",
       "location           object\n",
       "date               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the data type of spent to float\n",
    "sales['spent'] = sales['spent'].astype(float)\n",
    "\n",
    "# Check the data types of the DataFrame again\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4172b2",
   "metadata": {},
   "source": [
    "#### 2.1.4: Payment Method\n",
    "The payment method really isn't that important for what it is we're trying to find, so I'll go ahead and drop this column completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b51328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_id', 'item', 'quantity', 'price', 'spent', 'location',\n",
       "       'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the payment method column as it is not needed for the analysis\n",
    "sales.drop(columns=['pay_method'], inplace=True)\n",
    "\n",
    "# Check the columns of the DataFrame again\n",
    "sales.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab371322",
   "metadata": {},
   "source": [
    "#### 2.1.5: Location\n",
    "Location is a difficult one. It's fundamental to the analysis that we want to do, however it's a case by case data series once again. There are two options, the first it to simply remove the erroneous entries and move on. The second, and the choice I've opted for, is to aggregate the location based on the most common location for each item and replace any erroneous entries with the result. While it may not be the most accurate, it will give us the most amount of data possible for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b3a107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Takeaway', 'In-store', 'UNKNOWN', nan, 'ERROR'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values in the location column\n",
    "sales['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7714c0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>most_common_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cake</td>\n",
       "      <td>Takeaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coffee</td>\n",
       "      <td>Takeaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cookie</td>\n",
       "      <td>Takeaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Juice</td>\n",
       "      <td>In-store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salad</td>\n",
       "      <td>In-store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sandwich</td>\n",
       "      <td>In-store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smoothie</td>\n",
       "      <td>In-store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tea</td>\n",
       "      <td>In-store</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item most_common_location\n",
       "0      Cake             Takeaway\n",
       "1    Coffee             Takeaway\n",
       "2    Cookie             Takeaway\n",
       "3     Juice             In-store\n",
       "4     Salad             In-store\n",
       "5  Sandwich             In-store\n",
       "6  Smoothie             In-store\n",
       "7       Tea             In-store"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identifying the most common location for each product\n",
    "sales.groupby('item')['location'].agg(lambda x: x.value_counts().index[0]).reset_index(name='most_common_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d82555da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Takeaway', 'In-store'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing any UNKNOWN, ERROR and null values in the location column with the most common location for that item\n",
    "# Calculate the most common location for each item\n",
    "most_common_locations = sales.groupby('item')['location'].agg(lambda x: x.value_counts().index[0]).to_dict()\n",
    "\n",
    "# Replace UNKNOWN, ERROR, and NaN values in the location column\n",
    "sales['location'] = sales.apply(\n",
    "    lambda row: most_common_locations[row['item']] if pd.isnull(row['location']) or row['location'] in ['UNKNOWN', 'ERROR'] else row['location'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Check the unique values in the location column again\n",
    "sales['location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20804d",
   "metadata": {},
   "source": [
    "#### 2.1.6: Date\n",
    "Whilst the date column isn't explicitly needed, it's important to think ahead about what sort of analysis might be done in the future. We might like to look at the seasonality of sales or understand if the time of year affects the location of the purchase. In that case we will clean up the date column and make it easier to work with in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05d944d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2023-09-08', '2023-05-16', '2023-07-19', '2023-04-27',\n",
       "       '2023-06-11', '2023-03-31', '2023-10-28', '2023-12-31',\n",
       "       '2023-11-07', 'ERROR', '2023-05-03', '2023-06-01', '2023-03-21',\n",
       "       '2023-11-15', '2023-06-10', '2023-02-24', '2023-03-25',\n",
       "       '2023-01-15', '2023-03-30', '2023-12-01', '2023-09-18',\n",
       "       '2023-06-03', '2023-12-13', '2023-04-20', '2023-04-10',\n",
       "       '2023-03-11', '2023-06-02', '2023-11-06', '2023-08-15',\n",
       "       '2023-10-09', '2023-05-28', '2023-04-29', '2023-06-08',\n",
       "       '2023-06-29', '2023-04-17', '2023-12-22', '2023-01-10',\n",
       "       '2023-10-02', '2023-02-23', '2023-03-22', '2023-11-03',\n",
       "       '2023-03-02', '2023-06-26', '2023-05-02', '2023-09-05',\n",
       "       '2023-01-08', '2023-03-15', '2023-11-25', '2023-12-05',\n",
       "       '2023-06-27', '2023-10-07', '2023-09-30', '2023-05-27',\n",
       "       '2023-11-18', '2023-10-20', '2023-10-03', '2023-10-27',\n",
       "       '2023-01-31', '2023-12-08', '2023-06-19', '2023-12-14',\n",
       "       '2023-07-16', '2023-02-22', nan, '2023-06-15', '2023-12-09',\n",
       "       '2023-04-18', '2023-10-29', '2023-04-30', '2023-04-02',\n",
       "       '2023-05-24', '2023-03-12', '2023-08-16', '2023-09-10',\n",
       "       '2023-03-07', '2023-08-07', '2023-08-20', '2023-04-15',\n",
       "       '2023-07-25', '2023-10-30', '2023-12-15', '2023-02-25',\n",
       "       '2023-04-03', '2023-10-08', '2023-12-28', '2023-08-30',\n",
       "       '2023-02-03', '2023-09-12', '2023-05-04', '2023-02-21', 'UNKNOWN',\n",
       "       '2023-03-16', '2023-03-29', '2023-06-18', '2023-09-23',\n",
       "       '2023-01-14', '2023-09-14', '2023-09-16', '2023-02-06',\n",
       "       '2023-04-08', '2023-12-19', '2023-07-14', '2023-12-12',\n",
       "       '2023-01-05', '2023-01-23', '2023-02-20', '2023-12-06',\n",
       "       '2023-05-31', '2023-08-11', '2023-09-03', '2023-07-11',\n",
       "       '2023-06-06', '2023-01-18', '2023-03-23', '2023-06-23',\n",
       "       '2023-08-03', '2023-07-12', '2023-11-02', '2023-07-31',\n",
       "       '2023-09-19', '2023-02-09', '2023-05-21', '2023-07-02',\n",
       "       '2023-11-21', '2023-12-02', '2023-03-13', '2023-08-12',\n",
       "       '2023-02-16', '2023-03-26', '2023-11-01', '2023-07-22',\n",
       "       '2023-07-26', '2023-02-28', '2023-01-27', '2023-01-19',\n",
       "       '2023-04-07', '2023-03-20', '2023-12-27', '2023-10-26',\n",
       "       '2023-05-15', '2023-12-10', '2023-04-21', '2023-02-04',\n",
       "       '2023-11-12', '2023-08-05', '2023-05-10', '2023-07-15',\n",
       "       '2023-01-11', '2023-10-01', '2023-04-26', '2023-03-01',\n",
       "       '2023-11-13', '2023-07-09', '2023-05-13', '2023-05-18',\n",
       "       '2023-01-17', '2023-09-22', '2023-08-22', '2023-07-27',\n",
       "       '2023-12-21', '2023-09-28', '2023-11-16', '2023-04-14',\n",
       "       '2023-01-03', '2023-01-12', '2023-08-31', '2023-07-07',\n",
       "       '2023-09-15', '2023-10-21', '2023-09-02', '2023-08-19',\n",
       "       '2023-01-06', '2023-07-10', '2023-10-13', '2023-05-29',\n",
       "       '2023-05-22', '2023-11-23', '2023-11-14', '2023-12-17',\n",
       "       '2023-05-09', '2023-10-22', '2023-06-30', '2023-12-11',\n",
       "       '2023-04-25', '2023-10-12', '2023-07-04', '2023-01-28',\n",
       "       '2023-10-04', '2023-02-26', '2023-10-11', '2023-02-14',\n",
       "       '2023-09-06', '2023-04-23', '2023-01-22', '2023-03-10',\n",
       "       '2023-01-09', '2023-12-03', '2023-08-06', '2023-12-29',\n",
       "       '2023-02-15', '2023-05-25', '2023-10-31', '2023-02-27',\n",
       "       '2023-04-06', '2023-03-03', '2023-09-27', '2023-08-18',\n",
       "       '2023-05-12', '2023-07-06', '2023-08-09', '2023-05-14',\n",
       "       '2023-11-26', '2023-10-10', '2023-08-14', '2023-09-26',\n",
       "       '2023-01-13', '2023-10-16', '2023-11-17', '2023-12-20',\n",
       "       '2023-12-04', '2023-02-08', '2023-06-07', '2023-09-11',\n",
       "       '2023-02-01', '2023-02-12', '2023-03-14', '2023-09-29',\n",
       "       '2023-04-22', '2023-08-25', '2023-07-28', '2023-02-18',\n",
       "       '2023-06-13', '2023-12-24', '2023-03-28', '2023-02-11',\n",
       "       '2023-01-30', '2023-04-09', '2023-04-16', '2023-12-23',\n",
       "       '2023-03-05', '2023-03-24', '2023-07-23', '2023-07-29',\n",
       "       '2023-06-05', '2023-10-19', '2023-01-07', '2023-07-20',\n",
       "       '2023-05-07', '2023-08-10', '2023-10-24', '2023-08-13',\n",
       "       '2023-08-28', '2023-06-21', '2023-06-20', '2023-11-10',\n",
       "       '2023-10-18', '2023-05-19', '2023-07-17', '2023-06-24',\n",
       "       '2023-05-11', '2023-12-07', '2023-09-01', '2023-01-04',\n",
       "       '2023-12-16', '2023-09-25', '2023-03-06', '2023-06-22',\n",
       "       '2023-05-30', '2023-04-24', '2023-09-20', '2023-02-07',\n",
       "       '2023-05-05', '2023-02-10', '2023-10-25', '2023-10-05',\n",
       "       '2023-07-21', '2023-02-19', '2023-07-08', '2023-09-04',\n",
       "       '2023-10-14', '2023-06-28', '2023-09-09', '2023-08-21',\n",
       "       '2023-03-19', '2023-07-01', '2023-06-14', '2023-03-09',\n",
       "       '2023-11-08', '2023-09-13', '2023-05-23', '2023-11-29',\n",
       "       '2023-04-01', '2023-06-09', '2023-08-23', '2023-08-08',\n",
       "       '2023-12-26', '2023-08-27', '2023-05-26', '2023-06-16',\n",
       "       '2023-12-25', '2023-01-25', '2023-10-23', '2023-05-06',\n",
       "       '2023-01-29', '2023-08-29', '2023-02-02', '2023-07-24',\n",
       "       '2023-04-12', '2023-08-24', '2023-09-21', '2023-10-15',\n",
       "       '2023-05-01', '2023-02-05', '2023-01-24', '2023-01-02',\n",
       "       '2023-06-12', '2023-01-16', '2023-04-04', '2023-10-17',\n",
       "       '2023-03-04', '2023-06-17', '2023-04-11', '2023-03-18',\n",
       "       '2023-08-26', '2023-07-05', '2023-05-17', '2023-11-22',\n",
       "       '2023-08-17', '2023-11-19', '2023-11-27', '2023-06-04',\n",
       "       '2023-09-17', '2023-11-04', '2023-11-28', '2023-04-19',\n",
       "       '2023-11-09', '2023-06-25', '2023-07-18', '2023-12-18',\n",
       "       '2023-04-28', '2023-03-17', '2023-04-13', '2023-01-26',\n",
       "       '2023-08-04', '2023-05-08', '2023-11-24', '2023-12-30',\n",
       "       '2023-11-20', '2023-09-24', '2023-01-21', '2023-07-13',\n",
       "       '2023-03-08', '2023-09-07', '2023-11-30', '2023-08-02',\n",
       "       '2023-04-05', '2023-08-01', '2023-01-20', '2023-01-01',\n",
       "       '2023-10-06', '2023-11-11', '2023-02-13', '2023-07-30',\n",
       "       '2023-02-17', '2023-05-20', '2023-11-05', '2023-03-27',\n",
       "       '2023-07-03'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values in the date column\n",
    "sales['date'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e85331",
   "metadata": {},
   "source": [
    "As per usual we can see that there are some erroneous entries in the date column. As the date column is important, I'm reluctant to just go ahead and drop the rows. I think the best course of action would be get a feeling for how many erroneous and null values there are and, assuming there isn't too many, generate random dates between the start and end dates and use those to replace the erroneous entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c592ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 271)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of UNKNOWN, ERROR and null values in the date column\n",
    "sales['date'].isnull().sum(), sales['date'].str.contains('UNKNOWN|ERROR').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb385d1d",
   "metadata": {},
   "source": [
    "There isn't too many erroneous values, therefore I think our plan may work. The first thing I need to do is to isolate the erroneous rows, save them to a new data frame and then drop them from the main sales data. This will allow me to change the data type of the date column and find the start and end dates in the valid data. Then I'll generate the random dates in the seperated data and add them back into the main data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87a44a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the unknown, error and null values from the date column in new DataFrames\n",
    "sales_null = sales[sales['date'].isnull()]\n",
    "sales_error = sales[sales['date'].str.contains('UNKNOWN|ERROR', na=False)]\n",
    "\n",
    "# Drop the error, unknown and null values in the date column\n",
    "sales = sales[~sales['date'].isnull()]\n",
    "sales = sales[~sales['date'].str.contains('UNKNOWN|ERROR', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb6642e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id            object\n",
       "item                      object\n",
       "quantity                   int32\n",
       "price                    float64\n",
       "spent                    float64\n",
       "location                  object\n",
       "date              datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the data type of the date column to datetime\n",
    "sales['date'] = pd.to_datetime(sales['date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Check the data types of the DataFrame again\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06ab23f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2023-01-01 00:00:00'), Timestamp('2023-12-31 00:00:00'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the start and end dates of the data set\n",
    "start_date = sales['date'].min()\n",
    "end_date = sales['date'].max()\n",
    "\n",
    "# Check the start and end dates of the data set\n",
    "start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f54c5394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>item</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>spent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>TXN_2091733</td>\n",
       "      <td>Salad</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>In-store</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>TXN_7447872</td>\n",
       "      <td>Juice</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>In-store</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>TXN_1093800</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>TXN_6463132</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>TXN_1908636</td>\n",
       "      <td>Tea</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>In-store</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>TXN_7390866</td>\n",
       "      <td>Tea</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9769</th>\n",
       "      <td>TXN_9686177</td>\n",
       "      <td>Cake</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>In-store</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>TXN_5536245</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>In-store</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>TXN_8344810</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>In-store</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>TXN_9594133</td>\n",
       "      <td>Cake</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     transaction_id      item  quantity  price  spent  location date\n",
       "77      TXN_2091733     Salad         1    5.0    5.0  In-store  NaN\n",
       "104     TXN_7447872     Juice         2    3.0    6.0  In-store  NaN\n",
       "160     TXN_1093800  Sandwich         3    4.0   12.0  Takeaway  NaN\n",
       "175     TXN_6463132    Cookie         5    1.0    5.0  Takeaway  NaN\n",
       "246     TXN_1908636       Tea         2    1.5    3.0  In-store  NaN\n",
       "...             ...       ...       ...    ...    ...       ...  ...\n",
       "9766    TXN_7390866       Tea         5    1.5    7.5  Takeaway  NaN\n",
       "9769    TXN_9686177      Cake         3    3.0    9.0  In-store  NaN\n",
       "9833    TXN_5536245  Smoothie         4    4.0   16.0  In-store  NaN\n",
       "9931    TXN_8344810  Smoothie         2    4.0    8.0  In-store  NaN\n",
       "9988    TXN_9594133      Cake         5    3.0   15.0  Takeaway  NaN\n",
       "\n",
       "[142 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "463d5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random dates between the start and end date in the date column of the sales_null DataFrame\n",
    "sales_null['date'] = pd.to_datetime(\n",
    "    np.random.choice(pd.date_range(start_date, end_date, freq='D'), size=len(sales_null))\n",
    ")\n",
    "\n",
    "# Generate random dates between the start and end date in the date column of the sales_error DataFrame\n",
    "sales_error['date'] = pd.to_datetime(\n",
    "    np.random.choice(pd.date_range(start_date, end_date, freq='D'), size=len(sales_error))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38185ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2023-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2023-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2023-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>2023-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9769</th>\n",
       "      <td>2023-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>2023-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>2023-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date\n",
       "77   2023-01-18\n",
       "104  2023-01-23\n",
       "160  2023-02-25\n",
       "175  2023-03-03\n",
       "246  2023-02-23\n",
       "...         ...\n",
       "9766 2023-08-02\n",
       "9769 2023-06-18\n",
       "9833 2023-08-06\n",
       "9931 2023-04-25\n",
       "9988 2023-09-25\n",
       "\n",
       "[142 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the date column of the sales_null DataFrame\n",
    "sales_null[['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "661e77d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2023-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>2023-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9933</th>\n",
       "      <td>2023-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>2023-04-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date\n",
       "11   2023-04-19\n",
       "29   2023-06-07\n",
       "33   2023-01-05\n",
       "103  2023-12-17\n",
       "115  2023-11-02\n",
       "...         ...\n",
       "9907 2023-03-09\n",
       "9933 2023-11-30\n",
       "9937 2023-06-11\n",
       "9949 2023-11-09\n",
       "9983 2023-04-16\n",
       "\n",
       "[271 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the date column of the sales_error DataFrame\n",
    "sales_error[['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "465a8235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8634, 7), (142, 7), (271, 7))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heck the shape of the sales data before appending\n",
    "sales.shape, sales_null.shape, sales_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f538361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9047, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the sales_null and sales_error DataFrames to the sales DataFrame\n",
    "sales = pd.concat([sales, sales_null, sales_error], ignore_index=True)\n",
    "\n",
    "# Check the shape of the DataFrame again\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d793f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new csv containing the cleaned sales data\n",
    "sales.to_csv('cafe_sales_data_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020003d",
   "metadata": {},
   "source": [
    "There we have it. A fully cleaned sales data using a number of different methods in order to preserve as many rows of the data as possible. Now obviously there will be some implications of extrapolating out the location data and randomising the date data. But as these issues made up such a small part of the data, I believe that this data will be sufficient to accurately answer our initial questions and continue on to do a deeper analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
